<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Customer Discovery Guide · Gleb</title>
  <meta name="description" content="A complete system for reducing uncertainty about who your customer is, what problem is real, and what you should build next." />
  <script src="/assets/theme-init.js"></script>
  <link rel="stylesheet" href="/assets/style.css" />
  <link rel="icon" href="/assets/favicon.svg" />
</head>
<body>
  <header>
    <div class="wrap">
      <button class="menu-btn" type="button" data-menu-button aria-expanded="false" aria-label="Toggle navigation">
        Menu
      </button>
      <nav data-nav>
        <a href="/">Home</a>
        <a href="/projects/">Projects</a>
        <a href="/writing/" aria-current="page">Writing</a>
        <a href="/collections/">Collections</a>
        <a href="/about/">About</a>
      </nav>
    </div>
  </header>

  <div class="wrap">
    <main>
      <p class="small" style="margin-bottom: 18px;"><a class="button-link" href="/writing/">← Back to Writing</a></p>
      <div class="article-header">
        <p class="article-date">Jan 21, 2026</p>
        <h1>Customer Discovery Guide</h1>
        <p class="article-subtitle">A complete system for reducing uncertainty about who your customer is, what problem is real, and what you should build next.</p>
      </div>

      <p>If you are doing "customer discovery" but it feels like random calls, vague notes, and fake validation, you are not alone.</p>

      <p>Most teams fail for one reason: <strong>they collect opinions instead of evidence.</strong> Customer discovery is not "Do you like my idea?" It is <strong>a system for reducing uncertainty</strong> about who your customer is, what problem is real, and what you should build next.</p>

      <p>This guide gives you that system.</p>

      <h2>What customer discovery actually is (and what it is not)</h2>

      <p>Customer discovery is a loop:<br>
      <strong>Assumption → Interview → Evidence → Decision → Next assumption.</strong></p>

      <p>It is not:</p>
      <ul>
        <li>Asking users to design your product</li>
        <li>Pitching your idea</li>
        <li>Collecting feature requests</li>
        <li>Hunting for compliments</li>
      </ul>

      <p>Your job is to learn. You are looking for clues that <strong>confirm or deny</strong> your assumptions.</p>

      <h2>Start with assumptions or you will waste weeks</h2>

      <p>Founders, let's face it - we love jumping into calls.</p>

      <p>The problem is simple: without assumptions, you do not know what you are trying to learn. Write 3–5 assumptions as your discovery backlog, keep them short.</p>

      <h3>The minimum assumption set</h3>

      <ul>
        <li><strong>ICP:</strong> who has the pain</li>
        <li><strong>Problem:</strong> what pain is real and frequent</li>
        <li><strong>Workflow/Alternatives:</strong> what they do today</li>
        <li><strong>Blockers:</strong> what stops them from solving it</li>
        <li><strong>Differentiation:</strong> why you vs status quo</li>
        <li><strong>Monetization:</strong> what "worth paying" means</li>
        <li><strong>Acquisition:</strong> how you will reach them</li>
      </ul>

      <p>For each assumption, add: "If this is false, we will…".</p>

      <p>Example:</p>
      <ul>
        <li>Assumption: "Ops managers track vendor compliance in spreadsheets and hate audits."</li>
        <li>If false, we will: "Stop building audit features and focus on onboarding automation."</li>
      </ul>

      <p>Learn more on resources like <a href="https://talk2user.com/">talk2user.com</a>!</p>

      <h2>Pick what to test next (so discovery compounds)</h2>

      <p>You only need one rule: test the riskiest assumption first. Risk means if wrong, it kills or radically changes your plan.</p>

      <p>A simple status set that works:</p>
      <ul>
        <li>Testing (we do not know yet)</li>
        <li>Confirmed (enough consistent evidence)</li>
        <li>Rejected (enough consistent contradiction)</li>
      </ul>

      <p>Do not overthink scoring early. Focus on whether evidence is repeating.</p>

      <h2>Who to talk to (and how many interviews you actually need)</h2>

      <p>B2B: start in the middle. Talk to people who feel the pain daily and will actually answer you. Mid-level managers and ICs are usually better than C-suite early on.</p>

      <p><strong>Volume matters more than you think</strong></p>

      <p>You are not looking for a single "yes." You are looking for <strong>patterns</strong>.</p>

      <ul>
        <li>Consumer: expect noisy behavior. Talk to <strong>70–100</strong> people to see patterns.</li>
        <li>Early B2B: plan for <strong>20–30</strong> as a bare minimum to get signal (and cancellations).</li>
      </ul>

      <p>If you have done 7 calls and feel "validated," you are probably just excited.</p>

      <h2>How to find interviewees fast (without being annoying)</h2>

      <h3>Use three channels</h3>

      <ol>
        <li><strong>Your network:</strong> friends, investors, operators. Warm intros compound.</li>
        <li><strong>Where they already hang out:</strong> Slack groups, Discord, Reddit, conferences.</li>
        <li><strong>LinkedIn targeting:</strong> role + company type + geography.</li>
      </ol>

      <h3>The outreach message that gets replies</h3>

      <p>Ask for advice. Be clear you are not selling.</p>

      <p>Template:</p>
      <blockquote>
        <p>"I am researching how [role] handles [job]. I would love to learn from your experience. Could I ask you a few questions on a 20-minute call? I am not selling anything."</p>
      </blockquote>

      <h3>The referral question that scales discovery</h3>

      <p>End every call with:<br>
      <strong>"Is there anyone else you think I should talk to?"</strong></p>

      <p>Aim for 1–2 intros per interview. That is how you go from "hard" to "automatic."</p>

      <h2>Designing questions that do not produce lies</h2>

      <p>Most bad discovery comes from one mistake: <strong>You ask for opinions about the future.</strong> People are terrible at predicting future behavior. They are great at describing what they already did. So your default question format is:</p>

      <p><strong>"Tell me about the last time you…"</strong></p>

      <h3>Rules that keep questions clean</h3>

      <ul>
        <li><strong>Ask open-ended questions.</strong> Talk little. Let them talk.</li>
        <li>Prefer <strong>who / what / why / how</strong>. Avoid <strong>is / are / would / do you</strong>.</li>
        <li>Avoid "magic wand" questions. Customers cannot design solutions well.</li>
      </ul>

      <h3>A repeatable question stack (use this every time)</h3>

      <p>Pick one assumption. Then ask:</p>

      <ol>
        <li><strong>Trigger story</strong><br>
        "Tell me about the last time [problem] happened."</li>
        <li><strong>Workflow</strong><br>
        "Walk me through what you did, step by step."</li>
        <li><strong>Pain + intensity</strong><br>
        "What was hardest? How often does this happen?"</li>
        <li><strong>Current alternatives</strong><br>
        "How do you solve it today? What did you try before?"</li>
        <li><strong>Cost of the problem</strong><br>
        "What does this cost you: time, money, risk, stress, reputation?"</li>
        <li><strong>Decision criteria</strong><br>
        "When you choose a tool/process here, what matters most?"</li>
        <li><strong>Constraints and blockers</strong><br>
        "What stops you from fixing this properly today?"</li>
        <li><strong>Close</strong><br>
        "What should I have asked you that I did not?"</li>
      </ol>

      <p>That stack reliably produces real data.</p>

      <h2>Running the interview (the 30-minute playbook)</h2>

      <h3>Before</h3>

      <ul>
        <li>Prepare an outline, not a script.</li>
        <li>Record if allowed. Get transcript.</li>
        <li>Block 30 minutes. No distractions.</li>
      </ul>

      <h3>During</h3>

      <p>Your only job: <strong>listen more than you talk.</strong></p>

      <p>Tactics that work:</p>
      <ul>
        <li><strong>Do not pitch your product.</strong> Stay in their world.</li>
        <li>Double down with "why" when something matters.</li>
        <li>Repeat back what you heard. Let them correct you. Listen!</li>
        <li>Watch for emotions and workarounds. Hacks signal they have real pain.</li>
        <li>Avoid hypotheticals. Ask what they do now, or did last time.</li>
      </ul>

      <h3>After</h3>

      <p>Insights come from patterns, not one call.</p>

      <ul>
        <li>Write key takeaways immediately.</li>
        <li>Send a thank-you and keep them updated. Early interviewees become early users.</li>
        <li>Share notes with your team. Do not trap learning in one person's brain.</li>
      </ul>

      <h2>Synthesis that leads to decisions (not a notes graveyard)</h2>

      <p>Most teams fail here. They do calls, collect notes, and still do not know what to do next.</p>

      <p>Fix it by forcing structure.</p>

      <h3>For each assumption, write four things</h3>

      <ol>
        <li><strong>Evidence bullets:</strong> 2–4 bullets grounded in what was said</li>
        <li><strong>Contradictions:</strong> explicit counter-evidence (with quotes)</li>
        <li><strong>Known vs Unknown:</strong> what you learned vs what is still unclear</li>
        <li><strong>Next test:</strong> the next interview focus</li>
      </ol>

      <p>If you do this every time, your discovery stops being random. It becomes a compounding system.</p>

      <h3>Track "signal," not vibes</h3>

      <p>A simple per-assumption label works:</p>

      <ul>
        <li><strong>Supports</strong></li>
        <li><strong>Mixed</strong></li>
        <li><strong>Contradicts</strong></li>
        <li><strong>No evidence</strong></li>
      </ul>

      <p>Don't forget about sample size. If only 2 people said it, it is not relevant.</p>

      <h2>The mistakes that quietly ruin discovery</h2>

      <p>These show up in almost every startup:</p>

      <ul>
        <li>Pitching instead of learning</li>
        <li>Leading questions</li>
        <li>Yes/no questions without follow-ups</li>
        <li>Asking about future behavior</li>
        <li>Talking too much</li>
        <li>Ignoring negative reactions</li>
        <li>Interviewing the wrong people</li>
        <li>Group interviews</li>
        <li>Not synthesizing what you learned</li>
      </ul>

      <p>If you fix only one: <strong>stop asking "Would you use {your product description}?"</strong></p>

      <h2>Close</h2>

      <p>Customer discovery is not about being "good at interviews." It is about <strong>building a system</strong> that prevents you from wasting months building the wrong thing.</p>

      <p>If you try one thing after reading this, do this:<br>
      <strong>Write 3 assumptions, then schedule 5 calls this week to kill the riskiest one.</strong></p>

    </main>
    <hr />
    <div class="footer no-border">
      <div class="small">© 2025 Gleb Braverman</div>
    </div>
  </div>

  <script src="/assets/site.js" defer></script>
</body>
</html>
